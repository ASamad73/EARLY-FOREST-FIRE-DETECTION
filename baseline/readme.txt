We began with a baseline approach involving three different prompt strategies using the CLIP model. These strategies were implemented across three separate files: 26-baseline-verySimple-prompts.py, 26-baseline-normal-prompts.py, and 26-baseline_detailed_prompt.py. In each of these scripts, we utilized three image datasets—two sourced from Kaggle and one additional dataset provided by the instructor. To enhance the training data, we applied various data augmentation techniques, while the testing data was only resized as needed and left otherwise unaltered.

Our experiments focused on zero-shot inference using CLIP, with no model training involved. As such, both the augmented and non-augmented datasets can be interpreted as test sets, differing only in the preprocessing applied. We used prompts in each file with very similar lengths. In the case of very simple prompts, we observed an accuracy of 35% on the augmented dataset and 23% on the non-augmented dataset. These results indicate that simple prompts were largely ineffective at capturing meaningful representations, and overall performance remained poor.

In contrast, the use of normal prompts significantly improved the results. We achieved an accuracy of 80% on the augmented data and 83% on the non-augmented data. Similarly, when using highly detailed prompts, the model reached 80.7% accuracy on the augmented dataset and 88% on the non-augmented one. These results suggest that prompt quality plays a crucial role in the zero-shot performance of CLIP, with more descriptive and contextually rich prompts yielding significantly better outcomes.

The consistent trend across both the normal and detailed prompt experiments is that the non-augmented (i.e., original) data outperformed the augmented data. This aligns with the understanding that while augmentation is typically useful during training to improve generalization, it may introduce noise or distortions during inference, particularly in zero-shot settings. Since we did not fine-tune the model and relied solely on pre-trained weights for inference, the augmented images likely confused the model rather than aiding its understanding. This underscores the importance of aligning preprocessing techniques with the specific phase of the machine learning pipeline—augmentation may enhance training, but can hinder inference when misapplied.